{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed5d0c0c",
   "metadata": {},
   "source": [
    "## Installation\n",
    "- Clone Repo: [https://github.com/ultralytics/JSON2YOLO](https://github.com/ultralytics/JSON2YOLO)\n",
    "- Copy this file into the repo\n",
    "- Change dataset paths\n",
    "- Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84df42f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 3)) (1.24.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 4)) (4.7.0.72)\n",
      "Requirement already satisfied: pandas in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 5)) (1.5.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 6)) (9.4.0)\n",
      "Requirement already satisfied: pyYAML in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 8)) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from -r requirements.txt (line 9)) (4.65.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from pandas->-r requirements.txt (line 5)) (2022.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from requests->-r requirements.txt (line 8)) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from tqdm->-r requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\phili\\workspaces\\python\\envs\\json2yolo\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 5)) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\phili\\Workspaces\\Python\\Envs\\json2yolo\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1818511",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base = 'C:/Users/phili/git.haw-hamburg.de/trashberry/trash/object/data/detection/mattress_test_2'\n",
    "source_json_dir = dataset_base + 'annotations'\n",
    "source_train_dir = dataset_base + 'images'\n",
    "source_val_dir = dataset_base + 'images'\n",
    "source_test_dir = None\n",
    "output_dir = 'C:/Users/phili/git.haw-hamburg.de/trashberry/trash/object/data/detection/mattress_test_2_converted'\n",
    "use_segments = False\n",
    "label_map = [0,0,None,None,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a693b980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "from utils import *\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_image(filename, source_dir, output_dir):\n",
    "    out_dir = Path(output_dir)\n",
    "    if not out_dir.exists():\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    shutil.copyfile(Path(source_dir) / filename, out_dir / filename)\n",
    "\n",
    "def copy_image_as_type(filename, output_dir, train_dir = None, val_dir = None, test_dir = None):\n",
    "    out = Path(output_dir) / 'images'\n",
    "    if train_dir is not None and os.path.exists(Path(train_dir) / filename):\n",
    "        copy_image(filename, train_dir, out / 'train')\n",
    "        return 'train'\n",
    "    if val_dir is not None and os.path.exists(Path(val_dir) / filename):\n",
    "        copy_image(filename, val_dir, out / 'val')\n",
    "        return 'val'\n",
    "    if test_dir is not None and os.path.exists(Path(test_dir) / filename):\n",
    "        copy_image(filename, test_dir, out / 'test')\n",
    "        return 'test'\n",
    "    return None\n",
    "    \n",
    "def convert_coco_json(json_dir='../coco/annotations/', output_dir='../datasets/data', train_dir = None, val_dir = None, test_dir = None, use_segments=False, label_map=None, cls91to80=False):\n",
    "    save_dir = make_dirs(output_dir)  # output directory\n",
    "    coco80 = coco91_to_coco80_class()\n",
    "\n",
    "    # Import json\n",
    "    for json_file in sorted(Path(json_dir).resolve().glob('*.json')):\n",
    "        fn = Path(save_dir) / 'labels'# folder name\n",
    "        #fn.mkdir()\n",
    "        with open(json_file) as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        instance_count = {}\n",
    "        images ={}\n",
    "        \n",
    "        for img in data['images']:\n",
    "            #print(img['id'], \": \", img['file_name'])\n",
    "            img['image_type'] = copy_image_as_type(img['file_name'], save_dir, train_dir, val_dir, test_dir)\n",
    "            if img['image_type'] is not None:\n",
    "                label_dir = Path(output_dir) / 'labels' / img['image_type'] \n",
    "                if not label_dir.exists():\n",
    "                    label_dir.mkdir()\n",
    "            images[img['id']] = img\n",
    "        \n",
    "        # Create image-annotations dict\n",
    "        imgToAnns = defaultdict(list)\n",
    "        for ann in data['annotations']:\n",
    "            imgToAnns[ann['image_id']].append(ann)\n",
    "\n",
    "        # Write labels file\n",
    "        for img_id, anns in tqdm(imgToAnns.items(), desc=f'Annotations {json_file}'):\n",
    "            img = images[img_id]\n",
    "            h, w, f_name, f_type = img['height'], img['width'], img['file_name'], img['image_type']\n",
    "            \n",
    "            if f_type is None:\n",
    "                continue\n",
    "            bboxes = []\n",
    "            segments = []\n",
    "            for ann in anns:\n",
    "                # if ann['iscrowd']:\n",
    "                #     continue\n",
    "                # The COCO box format is [top left x, top left y, width, height]\n",
    "                box = np.array(ann['bbox'], dtype=np.float64)\n",
    "                box[:2] += box[2:] / 2  # xy top-left corner to center\n",
    "                box[[0, 2]] /= w  # normalize x\n",
    "                box[[1, 3]] /= h  # normalize y\n",
    "                if box[2] <= 0 or box[3] <= 0:  # if w <= 0 and h <= 0\n",
    "                    continue\n",
    "\n",
    "                cls = coco80[ann['category_id'] - 1] if cls91to80 else ann['category_id'] - 1  # class\n",
    "                if label_map is not None:\n",
    "                    cls = label_map[cls]\n",
    "                    if cls is None:\n",
    "                        continue\n",
    "                    \n",
    "                box = [cls] + box.tolist()\n",
    "                if box not in bboxes:\n",
    "                    bboxes.append(box)\n",
    "                # Segments\n",
    "                if use_segments:\n",
    "                    if len(ann['segmentation']) > 1:\n",
    "                        s = merge_multi_segment(ann['segmentation'])\n",
    "                        s = (np.concatenate(s, axis=0) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    else:\n",
    "                        s = [j for i in ann['segmentation'] for j in i]  # all segments concatenated\n",
    "                        s = (np.array(s).reshape(-1, 2) / np.array([w, h])).reshape(-1).tolist()\n",
    "                    s = [cls] + s\n",
    "                    if s not in segments:\n",
    "                        segments.append(s)\n",
    "            print(f\"Processed '{f_name}': {len(bboxes)} annotations\")\n",
    "            if f_type not in instance_count:\n",
    "                instance_count[f_type] = len(bboxes)\n",
    "            else:\n",
    "                instance_count[f_type] += len(bboxes)\n",
    "            # Write\n",
    "            with open((fn / f_type / f_name).with_suffix('.txt'), 'a') as file:\n",
    "                for i in range(len(bboxes)):\n",
    "                    line = *(segments[i] if use_segments else bboxes[i]),  # cls, box or segments\n",
    "                    file.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "        print(instance_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9e1b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_coco_json(source_json_dir, output_dir, source_train_dir, source_val_dir, source_test_dir, use_segments, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90763f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics_v8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "86fe5295cf5f64317a9f054ea187fc8f9ecdad103d92038d5c5503c6c50e47cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
